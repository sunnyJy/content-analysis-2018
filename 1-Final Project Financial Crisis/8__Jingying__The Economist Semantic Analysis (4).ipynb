{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:purple\"> The Economist Semantic Analysis (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #For stopwords\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "# to build tables\n",
    "import sys\n",
    "from astropy.table import Table\n",
    "\n",
    "# to calculate precisions F-measure\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/parser already exists, skipping download\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "[100%]Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> For information Extrutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECONOMIST_Token = pandas.read_csv('ECONOMIST_Token_Neat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECONOMIST_Token = ECONOMIST_Token.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Article</th>\n",
       "      <th>Token_Word</th>\n",
       "      <th>Remark_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Nuclear proliferation Misreading Iran</td>\n",
       "      <td>Leaders</td>\n",
       "      <td>\\n\\t\\t\\tSpecial report Iran's nuclear programm...</td>\n",
       "      <td>['Special', 'report', 'Iran', \"'s\", 'nuclear',...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>UN reform Fix it or scrap it</td>\n",
       "      <td>Leaders</td>\n",
       "      <td>\\n\\t\\t\\tMexico and the United States Shots acr...</td>\n",
       "      <td>['Mexico', 'and', 'the', 'United', 'States', '...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Spain and its regions A Catalan kerfuffle</td>\n",
       "      <td>Leaders</td>\n",
       "      <td>\\n\\t\\t\\tSpain and Catalonia Bad echoes from th...</td>\n",
       "      <td>['Spain', 'and', 'Catalonia', 'Bad', 'echoes',...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day                                      Title      Tag  \\\n",
       "0  2006      1   14      Nuclear proliferation Misreading Iran  Leaders   \n",
       "1  2006      1   14               UN reform Fix it or scrap it  Leaders   \n",
       "2  2006      1   14  Spain and its regions A Catalan kerfuffle  Leaders   \n",
       "\n",
       "                                             Article  \\\n",
       "0  \\n\\t\\t\\tSpecial report Iran's nuclear programm...   \n",
       "1  \\n\\t\\t\\tMexico and the United States Shots acr...   \n",
       "2  \\n\\t\\t\\tSpain and Catalonia Bad echoes from th...   \n",
       "\n",
       "                                          Token_Word Remark_Index  \n",
       "0  ['Special', 'report', 'Iran', \"'s\", 'nuclear',...           31  \n",
       "1  ['Mexico', 'and', 'the', 'United', 'States', '...           58  \n",
       "2  ['Spain', 'and', 'Catalonia', 'Bad', 'echoes',...           45  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECONOMIST_Token[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECONOMIST_Token[ECONOMIST_Token.Tag == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topics = ['Leaders', 'Britain', 'Europe', 'United States', 'The Americas', \n",
    "              'Middle East and Africa', 'Asia', 'Obituary',\n",
    "              'Business', 'Finance and economics', 'Science and technology', 'Books and arts']\n",
    "\n",
    "years = ['2006','2007','2008','2009','2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['Business', 'Finance and economics', 'Science and technology', 'Books and arts']\n",
    "\n",
    "serial = ['01','02','03','04','05','06','07','08','09','10','11','12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = years[1]  # 0,1,2,3,4\n",
    "topic = topics[0]  #0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "E_DF = ECONOMIST_Token[ECONOMIST_Token.Year ==int(y)][ECONOMIST_Token.Tag == topic]\n",
    "E_DF = E_DF.reset_index()\n",
    "del E_DF['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_DF['tokenized_sentences'] = E_DF['Article'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_DF['POS_sents'] = E_DF['tokenized_sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS counting function\n",
    "# input: corpus: the text to be analyzed\n",
    "# input: countTarget: the POS that you want to count;\n",
    "# input: top: number of top words tagged as countTarget\n",
    "# output: the list of top number of top words tagged as countTarget\n",
    "def POS_Counting(corpus, countTarget, top):\n",
    "    targetCounts = {}\n",
    "    for entry in corpus:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if kind != countTarget:\n",
    "                    continue\n",
    "                elif ent in targetCounts:\n",
    "                    targetCounts[ent] += 1\n",
    "                else:\n",
    "                    targetCounts[ent] = 1\n",
    "    sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table function POS_Table\n",
    "def POS_Table(count_list):\n",
    "    # count the number of nouns \n",
    "    word_NN = []\n",
    "    count_NN = []\n",
    "    word_VB = []\n",
    "    count_VB = []\n",
    "    word_JJ = []\n",
    "    count_JJ = []\n",
    "    for i in range(0,20):\n",
    "        word_NN.append(POS_Counting(count_list['POS_sents'], 'NN', 20)[i][0])\n",
    "        count_NN.append(POS_Counting(count_list['POS_sents'], 'NN', 20)[i][1])\n",
    "        word_VB.append(POS_Counting(count_list['POS_sents'], 'VB', 20)[i][0])\n",
    "        count_VB.append(POS_Counting(count_list['POS_sents'], 'VB', 20)[i][1])\n",
    "        word_JJ.append(POS_Counting(count_list['POS_sents'], 'JJ', 20)[i][0])\n",
    "        count_JJ.append(POS_Counting(count_list['POS_sents'], 'JJ', 20)[i][1])\n",
    "        t = Table([word_NN, count_NN,word_VB, count_VB,word_JJ, count_JJ], \n",
    "                  names=('NN', 'NN-count','VB','VB-count', 'JJ','JJ-count'))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_Table(E_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
